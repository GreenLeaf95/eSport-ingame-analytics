{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "808770ee",
   "metadata": {},
   "source": [
    "# Data Preprocessing & Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3901a4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sklearn\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e636fb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from ast import literal_eval\n",
    "from sklearn.metrics import accuracy_score\n",
    "from matplotlib import pyplot\n",
    "from xgboost import plot_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef1404a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('basis_dataset.csv', converters={\"gold_diff\": literal_eval,\n",
    "                                                \"kill_diff\": literal_eval,\n",
    "                                                \"dragon_diff\": literal_eval,\n",
    "                                                \"baron_diff\": literal_eval,\n",
    "                                                \"herald_diff\": literal_eval,\n",
    "                                                \"tower_diff\": literal_eval,\n",
    "                                                \"inhib_diff\": literal_eval,\n",
    "                                                \"gameId\": literal_eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7dbe5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244f7761",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce4f882",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Delete early surrenders (< 15 Min GameDuration)\n",
    "i = 0\n",
    "for rows in df.iterrows():\n",
    "    if len(rows[1][\"gold_diff\"]) < 15:\n",
    "        df.drop(df.index[i], inplace= True)\n",
    "        i +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7945f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete unnecessary columns\n",
    "df.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11032ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split basis_dataset into samples per min\n",
    "transformed_df = pd.DataFrame()\n",
    "transformed_df = df.convert_dtypes()\n",
    "final_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "valuelist = []\n",
    "minlist = []\n",
    "\n",
    "\n",
    "dfcontainer = []\n",
    "i = 0\n",
    "\n",
    "while i <= 60:\n",
    "    for cols in df.columns:\n",
    "        for rows in df.iterrows():\n",
    "            try:\n",
    "                value = rows[1][cols][i]\n",
    "                valuelist.append(value)\n",
    "                minlist.append(i)\n",
    "            except:\n",
    "                valuelist.append(\"N/A\")\n",
    "                minlist.append(i)\n",
    "\n",
    "        transformed_df[cols] = valuelist\n",
    "        transformed_df[\"timestamp\"] = minlist\n",
    "        valuelist = []\n",
    "        minlist = []\n",
    "\n",
    "    transformed_df[\"Team100win\"] = df.Team100win\n",
    "    transformed_df[\"gameId\"] = df.gameId\n",
    "    dfcontainer.append(transformed_df)\n",
    "    transformed_df = pd.DataFrame()\n",
    "    transformed_df = df.convert_dtypes()\n",
    "    i += 1\n",
    "bigdf = pd.concat(dfcontainer, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43d6d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9aea7cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Clear all rows with N/A\n",
    "bigdf.drop(bigdf[bigdf.gold_diff == \"N/A\"].index, inplace=True)\n",
    "bigdf.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f72e4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check cleaned dataset\n",
    "bigdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cbc0df",
   "metadata": {},
   "source": [
    "## Modeling Preliminary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abb5a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Train and Test Dataset / drop unnecessary columns\n",
    "\n",
    "#Train Dataset\n",
    "X = bigdf.drop([\"Team100win\", \"gameId\"], axis=1).copy()\n",
    "X = X.astype(int)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9767038",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Dataset\n",
    "y = pd.DataFrame(bigdf['Team100win'])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cf05ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,train_size=0.80, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bddac71",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xgb = xgb.XGBClassifier(objective='binary:logistic', missing=1, seed=42)\n",
    "\n",
    "clf_xgb.fit(X_train,\n",
    "            y_train,\n",
    "            verbose=True,\n",
    "            early_stopping_rounds=10,\n",
    "            eval_metric=\"aucpr\",\n",
    "            eval_set=[(X_test, y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2025728f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for test data\n",
    "y_pred = clf_xgb.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1a604c",
   "metadata": {},
   "source": [
    "## Model tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0510f34f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#eval on test&train set for learning curve\n",
    "evalset = [(X_train, y_train), (X_test,y_test)]\n",
    "clf_xgb = xgb.XGBClassifier(objective='binary:logistic', missing=1, seed=42)\n",
    "clf_xgb.fit(X_train,\n",
    "            y_train,\n",
    "            verbose=True,\n",
    "            early_stopping_rounds=10,\n",
    "            eval_metric=\"logloss\",\n",
    "            eval_set=evalset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627e9f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = clf_xgb.evals_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99014c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.plot(results['validation_0']['logloss'], label='train')\n",
    "pyplot.plot(results['validation_1']['logloss'], label='test')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452821cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find optimal hyperparameter with GridSearch\n",
    "param_grid = {\n",
    "    'max_depth': [10, 11, 12],\n",
    "    'learning_rate': [0.2],\n",
    "    'gamma': [0, 0.5, 0.25],\n",
    "    'reg_lambda': [0, 0.5, 0.25, 0.75]\n",
    "}\n",
    "\n",
    "\n",
    "optimal_params = GridSearchCV(\n",
    "    estimator=xgb.XGBClassifier(objective='binary:logistic',\n",
    "                               seed=42),\n",
    "    param_grid=param_grid,\n",
    "    scoring='roc_auc',\n",
    "    verbose=2,\n",
    "    n_jobs= 10,\n",
    "    cv=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3189498c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_params.fit(X_train,\n",
    "                  y_train,\n",
    "                  early_stopping_rounds=10,\n",
    "                  eval_metric='auc',\n",
    "                  eval_set=[(X_test, y_test)],\n",
    "                    verbose=False)\n",
    "\n",
    "print(optimal_params.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9437c67d",
   "metadata": {},
   "source": [
    "## Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af821d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xgb = xgb.XGBClassifier(objective='binary:logistic', \n",
    "                            missing=1, \n",
    "                            seed=42,\n",
    "                           gamma=0,\n",
    "                           learn_rate=0.2,\n",
    "                           max_depth=12,\n",
    "                           reg_lambda=0.5,\n",
    "                           subsample=1,\n",
    "                           colsample_bytree=1)\n",
    "\n",
    "clf_xgb.fit(X_train,\n",
    "            y_train,\n",
    "            verbose=True,\n",
    "            early_stopping_rounds=10,\n",
    "            eval_metric=\"aucpr\",\n",
    "            eval_set=[(X_test, y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaded7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for test data\n",
    "y_pred = clf_xgb.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d5ddb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(clf_xgb,\n",
    "                      X_test,\n",
    "                      y_test,\n",
    "                      values_format=\"d\",\n",
    "                      display_labels=[\"win\", \"lose\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f2218e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature importance\n",
    "plot_importance(clf_xgb)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbd90da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Single Game Prediction\n",
    "singlematch = bigdf[bigdf.gameId == 1490579]\n",
    "singlematch.drop([\"Team100win\", \"gameId\"], axis=1, inplace=True)\n",
    "singlematch.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9754d538",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_single = clf_xgb.predict_proba(singlematch)\n",
    "Team100 = results_single[:,0]\n",
    "Team200 = results_single[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3d4b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.plot(Team100, label=\"Team100\")\n",
    "pyplot.plot(Team200, label=\"Team200\")\n",
    "pyplot.xlabel('Minute', fontsize='x-large')\n",
    "pyplot.ylabel('Win probabilty', fontsize='x-large')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
